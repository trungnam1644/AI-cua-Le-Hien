import streamlit as st
import google.generativeai as genai

st.set_page_config(
    page_title="Trá»£ lÃ½ Quáº£n lÃ½ GiÃ¡o dá»¥c", 
    page_icon="ğŸ“", 
    layout="wide"
)

st.markdown("""
<style>
    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 25%, #f093fb 50%, #4facfe 75%, #00f2fe 100%);
        background-size: 400% 400%;
        animation: gradient 15s ease infinite;
    }
    
    @keyframes gradient {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    
    [data-testid="stChatMessageContent"] {
        background: rgba(255, 255, 255, 0.95) !important;
        backdrop-filter: blur(10px);
        border-radius: 20px;
        padding: 20px;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        border: 1px solid rgba(255, 255, 255, 0.3);
    }
    
    [data-testid="chatAvatarIcon-user"],
    [data-testid="chatAvatarIcon-assistant"] {
        background: rgba(255, 255, 255, 0.8) !important;
        backdrop-filter: blur(5px);
    }
    
    [data-testid="stChatMessage"] {
        background: transparent !important;
    }
    
    [data-testid="stChatMessageContent"] p,
    [data-testid="stChatMessageContent"] h1,
    [data-testid="stChatMessageContent"] h2,
    [data-testid="stChatMessageContent"] h3,
    [data-testid="stChatMessageContent"] li {
        color: #333 !important;
    }
    
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, rgba(102, 126, 234, 0.9) 0%, rgba(118, 75, 162, 0.9) 100%);
    }
    
    [data-testid="stSidebar"] [data-testid="stMarkdownContainer"] {
        color: white;
    }
    
    .stButton>button {
        background: linear-gradient(135deg, rgba(255, 255, 255, 0.3), rgba(255, 255, 255, 0.1));
        backdrop-filter: blur(10px);
        color: white;
        border: 2px solid rgba(255, 255, 255, 0.4);
        border-radius: 15px;
        padding: 12px 24px;
        font-weight: 600;
        font-size: 14px;
        width: 100%;
        transition: all 0.3s;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
    }
    
    .stButton>button:hover {
        background: linear-gradient(135deg, rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.3));
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3);
        border-color: rgba(255, 255, 255, 0.6);
    }
    
    .stChatInputContainer {
        background: rgba(255, 255, 255, 0.9);
        backdrop-filter: blur(10px);
        border-radius: 25px;
        border: 1px solid rgba(255, 255, 255, 0.3);
    }
    
    h1, h3 {
        color: white;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
    }
</style>
""", unsafe_allow_html=True)
#code by trungnam 
st.markdown("""
<div style='background: linear-gradient(135deg, rgba(255, 255, 255, 0.25), rgba(255, 255, 255, 0.1));
            backdrop-filter: blur(20px);
            padding: 40px;
            border-radius: 30px;
            text-align: center;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.2);
            border: 2px solid rgba(255, 255, 255, 0.3);
            margin-bottom: 30px;'>
    <h1 style='color: white; font-size: 3em; margin: 0; text-shadow: 3px 3px 6px rgba(0, 0, 0, 0.3);'>
        ğŸ“š Trá»£ lÃ½ Quáº£n lÃ½ GiÃ¡o dá»¥c ğŸ“
    </h1>
    <p style='color: white; font-size: 1.3em; margin: 15px 0 0 0; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);'>
        Há»— trá»£ Ban GiÃ¡m hiá»‡u phÃ¢n tÃ­ch vÃ  giáº£i quyáº¿t váº¥n Ä‘á» quáº£n lÃ½ nhÃ  trÆ°á»ng
    </p>
</div>
""", unsafe_allow_html=True)

try:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.5-flash')
except Exception as e:
    st.error(f"CÃ³ lá»—i xáº£y ra: {str(e)}")
    st.stop()

SYSTEM_PROMPT = """Báº¡n lÃ  trá»£ lÃ½ quáº£n lÃ½ giÃ¡o dá»¥c chuyÃªn nghiá»‡p, há»— trá»£ Ban GiÃ¡m hiá»‡u nhÃ  trÆ°á»ng.

NHIá»†M Vá»¤ Cá»¦A Báº N:
- PhÃ¢n tÃ­ch cÃ¡c váº¥n Ä‘á» quáº£n lÃ½ giÃ¡o dá»¥c má»™t cÃ¡ch chuyÃªn sÃ¢u, cÃ³ cáº¥u trÃºc
- ÄÆ°a ra giáº£i phÃ¡p cá»¥ thá»ƒ, kháº£ thi, dá»±a trÃªn nghiÃªn cá»©u quáº£n lÃ½ hiá»‡n Ä‘áº¡i
- Há»— trá»£ xÃ¢y dá»±ng káº¿ hoáº¡ch hÃ nh Ä‘á»™ng chi tiáº¿t
- Táº¡o tÃ i liá»‡u bÃ¡o cÃ¡o chuyÃªn nghiá»‡p

PHONG CÃCH GIAO TIáº¾P:
- ChuyÃªn nghiá»‡p, rÃµ rÃ ng, cÃ³ cáº¥u trÃºc bullet points
- Sá»­ dá»¥ng icon phÃ¹ há»£p: ğŸ“š ğŸ“Š ğŸ¯ ğŸ’¡ âœ… ğŸ“‹ ğŸ‘¥ ğŸ«
- ÄÆ°a ra lá»±a chá»n cá»¥ thá»ƒ cho ngÆ°á»i dÃ¹ng
- PhÃ¢n tÃ­ch nguyÃªn nhÃ¢n trÆ°á»›c khi Ä‘Æ°a giáº£i phÃ¡p

KHI NGÆ¯á»œI DÃ™NG CHá»ŒN Váº¤N Äá»€:
1. Liá»‡t kÃª 4-5 nguyÃªn nhÃ¢n cÃ³ thá»ƒ
2. ÄÆ°a ra 3 hÆ°á»›ng há»— trá»£ cá»¥ thá»ƒ
3. Khi Ä‘Æ°á»£c yÃªu cáº§u, cung cáº¥p 5 biá»‡n phÃ¡p chi tiáº¿t

KHI ÄÆ¯á»¢C YÃŠU Cáº¦U Táº O TÃ€I LIá»†U:
- Káº¿ hoáº¡ch: Format rÃµ rÃ ng, cÃ³ má»¥c tiÃªu, hoáº¡t Ä‘á»™ng, thá»i gian
- BÃ¡o cÃ¡o: Cáº¥u trÃºc Ä‘áº§y Ä‘á»§ vá»›i tÃ¬nh huá»‘ng, nguyÃªn nhÃ¢n, giáº£i phÃ¡p
- Checklist: Chia theo tuáº§n, cá»¥ thá»ƒ, cÃ³ trÃ¡ch nhiá»‡m

LUÃ”N GIá»® THÃI Äá»˜: TÃ´n trá»ng, há»— trá»£, khÃ´ng phÃ¡n xÃ©t."""

if "messages" not in st.session_state:
    st.session_state.messages = []

if len(st.session_state.messages) == 0:
    welcome_message = """ğŸ‘‹ Xin chÃ o Ban GiÃ¡m hiá»‡u!

TÃ´i lÃ  trá»£ lÃ½ quáº£n lÃ½ giÃ¡o dá»¥c. NhÃ  trÆ°á»ng Ä‘ang gáº·p 3 váº¥n Ä‘á» ná»•i báº­t gáº§n Ä‘Ã¢y. Báº¡n muá»‘n phÃ¢n tÃ­ch váº¥n Ä‘á» nÃ o trÆ°á»›c?

**1. Cháº¥t lÆ°á»£ng giáº£ng dáº¡y cá»§a má»™t sá»‘ tá»• chuyÃªn mÃ´n giáº£m sÃºt**

**2. Báº¥t Ä‘á»“ng quan Ä‘iá»ƒm giá»¯a cÃ¡c nhÃ³m giÃ¡o viÃªn tháº¿ há»‡ khÃ¡c nhau**

**3. Má»©c Ä‘á»™ tham gia hoáº¡t Ä‘á»™ng chung khÃ´ng Ä‘á»“ng Ä‘á»u**

---

HÃ£y chá»n sá»‘ **1, 2, 3** hoáº·c mÃ´ táº£ váº¥n Ä‘á» khÃ¡c báº¡n Ä‘ang gáº·p pháº£i."""
    
    st.session_state.messages.append({"role": "assistant", "content": welcome_message})

# Kiá»ƒm tra xem cÃ³ message má»›i tá»« button sidebar khÃ´ng
if "pending_response" not in st.session_state:
    st.session_state.pending_response = False

# Hiá»ƒn thá»‹ táº¥t cáº£ messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Xá»­ lÃ½ AI response náº¿u cÃ³ message má»›i tá»« button
if st.session_state.pending_response and len(st.session_state.messages) > 0:
    last_message = st.session_state.messages[-1]
    if last_message["role"] == "user":
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            try:
                conversation_history = ""
                for msg in st.session_state.messages:
                    role = "NgÆ°á»i dÃ¹ng" if msg["role"] == "user" else "Trá»£ lÃ½"
                    conversation_history += f"{role}: {msg['content']}\n\n"
                
                full_prompt = f"""{SYSTEM_PROMPT}

Lá»ŠCH Sá»¬ Há»˜I THOáº I:
{conversation_history}

Ban GiÃ¡m hiá»‡u vá»«a há»i: {last_message['content']}

HÃ£y tráº£ lá»i theo vai trÃ² trá»£ lÃ½ quáº£n lÃ½ giÃ¡o dá»¥c chuyÃªn nghiá»‡p. PhÃ¢n tÃ­ch váº¥n Ä‘á» vÃ  Ä‘Æ°a ra cÃ¡c lá»±a chá»n há»— trá»£ cá»¥ thá»ƒ."""
                
                # Streaming response
                response = model.generate_content(full_prompt, stream=True)
                for chunk in response:
                    if chunk.text:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "â–Œ")
                
                message_placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                
            except Exception as e:
                error_message = f"CÃ³ lá»—i xáº£y ra: {str(e)}"
                message_placeholder.markdown(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})
        
        st.session_state.pending_response = False
        st.rerun()

# Xá»­ lÃ½ input tá»« chat
if prompt := st.chat_input("Nháº­p tin nháº¯n cá»§a báº¡n..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            conversation_history = ""
            for msg in st.session_state.messages:
                role = "NgÆ°á»i dÃ¹ng" if msg["role"] == "user" else "Trá»£ lÃ½"
                conversation_history += f"{role}: {msg['content']}\n\n"
            
            full_prompt = f"""{SYSTEM_PROMPT}

Lá»ŠCH Sá»¬ Há»˜I THOáº I:
{conversation_history}

Ban GiÃ¡m hiá»‡u vá»«a há»i: {prompt}

HÃ£y tráº£ lá»i theo vai trÃ² trá»£ lÃ½ quáº£n lÃ½ giÃ¡o dá»¥c chuyÃªn nghiá»‡p. PhÃ¢n tÃ­ch váº¥n Ä‘á» vÃ  Ä‘Æ°a ra cÃ¡c lá»±a chá»n há»— trá»£ cá»¥ thá»ƒ."""
            
            # Streaming response
            response = model.generate_content(full_prompt, stream=True)
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            error_message = f"CÃ³ lá»—i xáº£y ra: {str(e)}"
            message_placeholder.markdown(error_message)
            st.session_state.messages.append({"role": "assistant", "content": error_message})

with st.sidebar:
    st.markdown("### ğŸ’ CÃ´ng cá»¥ quáº£n lÃ½")
    st.markdown("---")
    
    st.markdown("#### ğŸ« Váº¥n Ä‘á» phá»• biáº¿n")
    
    if st.button("ğŸ“Š Cháº¥t lÆ°á»£ng giáº£ng dáº¡y"):
        prompt = "PhÃ¢n tÃ­ch váº¥n Ä‘á»: Cháº¥t lÆ°á»£ng giáº£ng dáº¡y cá»§a má»™t sá»‘ tá»• chuyÃªn mÃ´n giáº£m sÃºt"
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.pending_response = True
        st.rerun()
    
    if st.button("ğŸ‘¥ Báº¥t Ä‘á»“ng tháº¿ há»‡"):
        prompt = "PhÃ¢n tÃ­ch váº¥n Ä‘á»: Báº¥t Ä‘á»“ng quan Ä‘iá»ƒm giá»¯a cÃ¡c nhÃ³m giÃ¡o viÃªn tháº¿ há»‡ khÃ¡c nhau"
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.pending_response = True
        st.rerun()
    
    if st.button("ğŸ¯ Tham gia hoáº¡t Ä‘á»™ng"):
        prompt = "PhÃ¢n tÃ­ch váº¥n Ä‘á»: Má»©c Ä‘á»™ tham gia hoáº¡t Ä‘á»™ng chung khÃ´ng Ä‘á»“ng Ä‘á»u"
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.pending_response = True
        st.rerun()
    
    st.markdown("---")
    st.markdown("#### ğŸ“ TÃ i liá»‡u há»— trá»£")
    
    if st.button("ğŸ“‹ Káº¿ hoáº¡ch can thiá»‡p"):
        prompt = "Viáº¿t káº¿ hoáº¡ch can thiá»‡p 1 trang cho váº¥n Ä‘á» Ä‘ang tháº£o luáº­n"
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.pending_response = True
        st.rerun()
    
    if st.button("ğŸ“ˆ BÃ¡o cÃ¡o phÃ¢n tÃ­ch"):
        prompt = "XÃ¢y dá»±ng bÃ¡o cÃ¡o phÃ¢n tÃ­ch tÃ¬nh huá»‘ng chi tiáº¿t"
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.pending_response = True
        st.rerun()
    
    if st.button("âœ… Checklist 30 ngÃ y"):
        prompt = "Táº¡o checklist viá»‡c cáº§n lÃ m trong 30 ngÃ y"
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.pending_response = True
        st.rerun()
    
    if st.button("ğŸ“„ TÃ i liá»‡u bÃ¡o cÃ¡o GV"):
        prompt = "Táº¡o tÃ i liá»‡u Ä‘á»ƒ bÃ¡o cÃ¡o cho giÃ¡o viÃªn"
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.pending_response = True
        st.rerun()
    
    st.markdown("---")
    
    if st.button("ğŸ”„ Cuá»™c trÃ² chuyá»‡n má»›i"):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    st.markdown("**ğŸ’ Táº¡o bá»Ÿi LeHien**")
    st.markdown("**ğŸŒ¸TN DÃ nh táº·ng cÃ´ giÃ¡o máº§m non**")
